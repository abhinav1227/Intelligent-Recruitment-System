{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zummit Infolabs Bangalore\n",
    "## Project 2 :- Inteligent Recruitment System\n",
    "1. Resume Phrasing\n",
    "2. Interview\n",
    "\n",
    "### Part-1 (Resume Phrasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the Training ML-NLP Model -\n",
    "import joblib\n",
    "tfidf = joblib.load(\"ResumeFraserModelEncoding.pkl\")\n",
    "model = joblib.load(\"ResumePhrasingModel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type/Enter/Paste Your Resume Here in Text Format: \n",
      "Skills Programming Languages Python pandas numpy scipy scikit learn matplotlib Sql Java JavaScript JQuery Machine learning Regression SVM Na ve Bayes KNN Random Forest Decision Trees Boosting techniques Cluster Analysis Word Embedding Sentiment Analysis Natural Language processing Dimensionality reduction Topic Modelling LDA NMF PCA Neural Nets Database Visualizations Mysql SqlServer Cassandra Hbase ElasticSearch D3 js DC js Plotly kibana matplotlib ggplot Tableau Others Regular Expression HTML CSS Angular 6 Logstash Kafka Python Flask Git Docker computer vision Open CV and understanding of Deep learning Education Details Data Science Assurance Associate Data Science Assurance Associate Ernst Young LLP Skill Details JAVASCRIPT Exprience 24 months jQuery Exprience 24 months Python Exprience 24 monthsCompany Details company Ernst Young LLP description Fraud Investigations and Dispute Services Assurance TECHNOLOGY ASSISTED REVIEW TAR Technology Assisted Review assists in a elerating the review process and run analytics and generate reports Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain this tool implements predictive coding and topic modelling by automating reviews resulting in reduced labor costs and time spent during the lawyers review Understand the end to end flow of the solution doing research and development for classification models predictive analysis and mining of the information present in text data Worked on analyzing the outputs and precision monitoring for the entire tool TAR assists in predictive coding topic modelling from the evidence by following EY standards Developed the classifier models in order to identify red flags and fraud related issues Tools Technologies Python scikit learn tfidf word2vec doc2vec cosine similarity Na ve Bayes LDA NMF for topic modelling Vader and text blob for sentiment analysis Matplot lib Tableau dashboard for reporting MULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS USA CLIENTS TEXT ANALYTICS MOTOR VEHICLE CUSTOMER REVIEW DATA Received customer feedback survey data for past one year Performed sentiment Positive Negative Neutral and time series analysis on customer comments across all 4 categories Created heat map of terms by survey category based on frequency of words Extracted Positive and Negative words across all the Survey categories and plotted Word cloud Created customized tableau dashboards for effective reporting and visualizations CHATBOT Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation reservation options and so on This chat bot serves entire product related questions Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant recommended questions Tools Technologies Python Natural language processing NLTK spacy topic modelling Sentiment analysis Word Embedding scikit learn JavaScript JQuery SqlServer INFORMATION GOVERNANCE Organizations to make informed decisions about all of the information they store The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk Scan data from multiple sources of formats and parse different file formats extract Meta data information push results for indexing elastic search and created customized interactive dashboards using kibana Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant Outdated or Trivial Preforming full text search analysis on elastic search with predefined methods which can tag as PII personally identifiable information social security numbers addresses names etc which frequently targeted during cyber attacks Tools Technologies Python Flask Elastic Search Kibana FRAUD ANALYTIC PLATFORM Fraud Analytics and investigative platform to review all red flag cases FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems It can be used by clients to interrogate their A ounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics Tools Technologies HTML JavaScript SqlServer JQuery CSS Bootstrap Node js D3 js DC js\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "Job Application for Position: data science\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "Congratulations Your resume is got selected for !! Data Science !! Profile. Stage-1\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "-------------------------------------------->>Final Result<<-----------------------------------------------------------\n",
      "Please Note That: \n",
      " If the Position that you applied for and the Model Predicted Position is Same then & then only You are Selected for Next Stage of Recruitment. \n",
      " Else Please Note that Your Application is Rejected\n",
      "-----------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Prediction on User Input -\n",
    "resume = input(\"Type/Enter/Paste Your Resume Here in Text Format: \\n\")\n",
    "prediction = model.predict(tfidf.transform([resume]))\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------\")\n",
    "position = input(\"Job Application for Position: \").capitalize()\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------------\")\n",
    "try:   \n",
    "    if prediction == 15:\n",
    "        print(\"Congratulations Your resume is got selected for !! Java Developer !! Profile. Stage-1\")\n",
    "    if prediction == 23: \n",
    "        print(\"Congratulations Your resume is got selected for !! Selenium Testing !! Profile. Stage-1\")\n",
    "    if prediction == 8:\n",
    "        print(\"Congratulations Your resume is got selected for !! DevOps Engineer !! Profile. Stage-1\")\n",
    "    if prediction == 20:\n",
    "        print(\"Congratulations Your resume is got selected for !! Python Developer !! Profile. Stage-1\")\n",
    "    if prediction == 24:\n",
    "        print(\"Congratulations Your resume is got selected for !! Web Designing !! Profile. Stage-1\")\n",
    "    if prediction == 12:\n",
    "        print(\"Congratulations Your resume is got selected for !! Human Resource !! Profile. Stage-1\")\n",
    "    if prediction == 13:\n",
    "        print(\"Congratulations Your resume is got selected for !! Hadoop !! Profile. Stage-1\")\n",
    "    if prediction == 18:\n",
    "        print(\"Congratulations Your resume is got selected for !! Operations Manager !! Profile. Stage-1\")\n",
    "    if prediction == 6:\n",
    "        print(\"Congratulations Your resume is got selected for !! Data Science !! Profile. Stage-1\")\n",
    "    if prediction == 22:\n",
    "        print(\"Congratulations Your resume is got selected for !! Sales !! Profile. Stage-1\")\n",
    "    if prediction == 3:\n",
    "        print(\"Congratulations Your resume is got selected for !! Block Chain !! Profile. Stage-1\")\n",
    "    if prediction == 10:\n",
    "        print(\"Congratulations Your resume is got selected for !! ETL Developer !! Profile. Stage-1\")\n",
    "    if prediction == 16:\n",
    "        print(\"Congratulations Your resume is got selected for !! Mechanical Engineer !! Profile. Stage-1\")\n",
    "    if prediction == 1:\n",
    "        print(\"Congratulations Your resume is got selected for !! Arts Professional !! Profile. Stage-1\")\n",
    "    if prediction == 7:\n",
    "        print(\"Congratulations Your resume is got selected for !! Database Engineer !! Profile. Stage-1\")\n",
    "    if prediction == 11:\n",
    "        print(\"Congratulations Your resume is got selected for !! Electrical Engineer !! Profile. Stage-1\")\n",
    "    if prediction == 14:\n",
    "        print(\"Congratulations Your resume is got selected for !! Health and fitness !! Profile. Stage-1\")\n",
    "    if prediction == 19:\n",
    "        print(\"Congratulations Your resume is got selected for !! PMO !! Profile. Stage-1\")\n",
    "    if prediction == 4:\n",
    "        print(\"Congratulations Your resume is got selected for !! Business/Data Analyst !! Profile. Stage-1\")\n",
    "    if prediction == 9:\n",
    "        print(\"Congratulations Your resume is got selected for !! DotNet Developer !! Profile. Stage-1\")\n",
    "    if prediction == 2:\n",
    "        print(\"Congratulations Your resume is got selected for !! Automation Testing !! Profile. Stage-1\")\n",
    "    if prediction == 17:\n",
    "        print(\"Congratulations Your resume is got selected for !! Network Security Engineer !! Profile. Stage-1\")\n",
    "    if prediction == 21:\n",
    "        print(\"Congratulations Your resume is got selected for !! SAP Developer !! Profile. Stage-1\")\n",
    "    if prediction == 5:\n",
    "        print(\"Congratulations Your resume is got selected for !! Civil Engineer !! Profile. Stage-1\")\n",
    "    if prediction == 0:\n",
    "        print(\"Congratulations Your resume is got selected for !! Advocate !! Profile. Stage-1\")\n",
    "except:\n",
    "    print(\"Sorry!!! Your Application is got Rejected.\")\n",
    "finally:\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------->>Final Result<<-----------------------------------------------------------\")\n",
    "    print(\"Please Note That: \\n If the Position that you applied for and the Model Predicted Position is Same then & then only You are Selected for Next Stage of Recruitment. \\n Else Please Note that Your Application is Rejected\")\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvmzYvLA3UxS"
   },
   "source": [
    "### Part 2- (Interview)\n",
    "\n",
    "## *The interview consists of comprehensive two-round technical interview process that blends technical and HR questions. The first round features multiple-choice questions, while the second round involves descriptive questions.*\n",
    "\n",
    "## **2.1: MCQ interview round:** In this stage, the candidate is given a set of multiple-choice questions to answer. The questions are designed to assess the candidate's knowledge, technical skills, and other relevant competencies. The answers provided by the candidate are then scored based on predefined criteria.\n",
    "\n",
    "## **2.2: Descriptive interview round:** In this stage, the candidate is given a set of questions to answer in a written format. The questions are designed to assess the candidate's grip upon the subject, communication skills, critical thinking abilities, problem-solving skills, and other relevant competencies. The answers provided by the candidate are then scored based on predefined criteria.\n",
    "\n",
    "### ***Once the candidate has completed all the stages of evaluation, their scores from each stage are combined to create a cumulative score. The cumulative score is then compared to a predefined threshold score to determine whether the candidate should be selected or rejected. If the candidate's cumulative score is above the threshold, they are selected for the position. If their score is below the threshold, they are rejected.***\n",
    "\n",
    "*`Note: It's important to note that the criteria used for scoring in each stage is based on the specific requirements of the job and the skills and competencies needed for success in that role. Additionally, the threshold score for selection or rejection is set based on the company's hiring goals and the competitiveness of the job market.`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aqHA1tFm3bhf"
   },
   "outputs": [],
   "source": [
    "# # Dependencies\n",
    "\n",
    "# !pip install transformers\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !pip install scikit-fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SdImjgGA3q3v",
    "outputId": "163f4292-90a9-44ad-d4a1-6e55eacb2ea5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import spacy\n",
    "import torch\n",
    "import transformers\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m52SV-So3p6n"
   },
   "source": [
    "## 2.1: MCQ interview round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lf-Amtxarep1"
   },
   "outputs": [],
   "source": [
    "#Load the JSON file\n",
    "with open('mcq_questiosn.json', 'r') as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "# for item in questions:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gPnEPqKProGr"
   },
   "outputs": [],
   "source": [
    "# json_str = json.dumps(questions, indent=4)\n",
    "# print(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0aTRVd8ronP",
    "outputId": "c5827114-bcfe-45ad-ac21-92d36535079d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the first round of interview!\n",
      "\n",
      "What is your name?Bot\n",
      "\n",
      "Hello, Bot! Congratulations for qualifying to this round!\n",
      "\n",
      "This is an integrated Technical + HR round.\n",
      "\n",
      "We will ask you a series of MCQ questions. \n",
      "Please provide your response to each question, and we will evaluate your answer on a scale of 1 to 10.\n",
      "Every correct answer will award you +1 point and wrong will award you 0.\n",
      "\n",
      "Bot. Let's get started.\n",
      "\n",
      "Technical Section\n",
      "\n",
      "What is the difference between batch gradient descent and stochastic gradient descent in machine learning?\n",
      "A: Batch gradient descent updates the parameters after computing the gradients on the entire dataset, while stochastic gradient descent updates the parameters after computing the gradients on a single data point.\n",
      "B: Batch gradient descent updates the parameters after computing the gradients on a random subset of the dataset, while stochastic gradient descent updates the parameters after computing the gradients on the entire dataset.\n",
      "C: Batch gradient descent updates the parameters after computing the gradients on a single data point, while stochastic gradient descent updates the parameters after computing the gradients on the entire dataset.\n",
      "D: Batch gradient descent and stochastic gradient descent are the same thing.\n",
      "Enter your answer (A/B/C/D): A\n",
      "\n",
      "\n",
      "What is the purpose of dropout regularization in deep learning?\n",
      "A: To randomly select a subset of features to use in the model during training\n",
      "B: To prevent overfitting by randomly dropping out neurons during training\n",
      "C: To increase the number of layers in a deep neural network\n",
      "D: To decrease the learning rate during training\n",
      "Enter your answer (A/B/C/D): A\n",
      "\n",
      "\n",
      "What is the purpose of the activation function in a neural network?\n",
      "A: To determine the learning rate during training\n",
      "B: To normalize the input data\n",
      "C: To perform feature selection on the input data\n",
      "D: To introduce nonlinearity into the model\n",
      "Enter your answer (A/B/C/D): A\n",
      "\n",
      "\n",
      "What is the difference between L1 and L2 regularization in machine learning?\n",
      "A: L1 regularization penalizes the absolute value of the weights, while L2 regularization penalizes the squared value of the weights.\n",
      "B: L1 regularization penalizes the squared value of the weights, while L2 regularization penalizes the absolute value of the weights.\n",
      "C: L1 regularization penalizes the number of non-zero weights, while L2 regularization penalizes the sum of the squared weights.\n",
      "D: L1 regularization and L2 regularization are the same thing.\n",
      "Enter your answer (A/B/C/D): A\n",
      "\n",
      "\n",
      "What is the purpose of the softmax function in deep learning?\n",
      "A: To perform feature selection on the input data\n",
      "B: To introduce nonlinearity into the mode\n",
      "C: To convert the output of a neural network into a probability distribution over multiple classes\n",
      "D: To normalize the input data\n",
      "Enter your answer (A/B/C/D): A\n",
      "\n",
      "\n",
      "\n",
      "HR Section\n",
      "\n",
      "You are a team leader and notice that one of your team members is consistently missing deadlines. How do you handle the situation?\n",
      "A: Confront the team member in front of everyone and ask why they are not meeting deadlines\n",
      "B: Ignore the issue and hope it resolves itself\n",
      "C: Schedule a private meeting with the team member to discuss the issue and work together to find a solution\n",
      "D: Assign more tasks to the team member to keep them bus\n",
      "Enter your answer (A/B/C/D): A\n",
      "\n",
      "\n",
      "A coworker approaches you and tells you that they are feeling overwhelmed and stressed out. What do you do?\n",
      "A: Listen to the coworker and offer support and resources to help manage their stress\n",
      "B: Suggest that the coworker take some time off to relax\n",
      "C: Tell the coworker to toughen up and deal with it\n",
      "D: Ignore the coworker and continue with your work\n",
      "Enter your answer (A/B/C/D): A\n",
      "\n",
      "\n",
      "You receive a work assignment that you have never done before and are unsure how to proceed. What do you do?\n",
      "A: Turn in a half-hearted attempt and hope for the best\n",
      "B: Ask your coworker to do the assignment for you\n",
      "C: Give up and don't complete the assignment\n",
      "D: Seek guidance from your supervisor or a more experienced colleague\n",
      "Enter your answer (A/B/C/D): A\n",
      "\n",
      "\n",
      "You are in a meeting with a colleague who keeps interrupting and talking over you. What do you do?\n",
      "A: Talk louder and try to talk over your colleague\n",
      "B: Politely ask your colleague to let you finish speaking before they respond\n",
      "C: Ignore the behavior and hope it stops on its own\n",
      "D: Call out your colleague and tell them to stop interrupting\n",
      "Enter your answer (A/B/C/D): A\n",
      "\n",
      "\n",
      "A coworker approaches you with a complaint about another coworker. What do you do?\n",
      "A: Listen to the complaint and offer support, but encourage the coworker to bring the issue to a supervisor\n",
      "B: Tell the coworker to stop complaining and focus on their own work\n",
      "C: Confront the other coworker about the complaint and try to resolve the issue\n",
      "D: Ignore the complaint and tell the coworker to deal with it themselves\n",
      "Enter your answer (A/B/C/D): A\n",
      "\n",
      "\n",
      "\n",
      "Your final score is 4/10\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome to the first round of interview!\\n\")\n",
    "candidate_name = input(\"What is your name?\")\n",
    "print(\"\\nHello, \" + candidate_name + \"! Congratulations for qualifying to this round!\")\n",
    "print(\"\"\"\n",
    "This is an integrated Technical + HR round.\n",
    "\n",
    "We will ask you a series of MCQ questions. \n",
    "Please provide your response to each question, and we will evaluate your answer on a scale of 1 to 10.\n",
    "Every correct answer will award you +1 point and wrong will award you 0.\n",
    "\"\"\")\n",
    "print(candidate_name + \". Let's get started.\")\n",
    "\n",
    "# Rename categories\n",
    "questions[\"Technical Section\"] = questions.pop(\"Tech_MCQ\")\n",
    "questions[\"HR Section\"] = questions.pop(\"HR_MCQ\")\n",
    "\n",
    "score = []\n",
    "count = 0\n",
    "# Iterate through the categories (Tech_MCQ and HR_MCQ)\n",
    "for category in ['Technical Section', 'HR Section']:\n",
    "    print(f\"\\n{category}\\n\")\n",
    "    \n",
    "    # Iterate through the questions in each category\n",
    "    for question in questions[category]:\n",
    "        print(question)\n",
    "        for option in questions[category][question]:\n",
    "            if option != \"Answer\":\n",
    "                print(f\"{option}: {questions[category][question][option]}\")\n",
    "        answer = input(\"Enter your answer (A/B/C/D): \")\n",
    "        \n",
    "        # Check if the answer is correct and update the score accordingly\n",
    "        if answer == questions[category][question][\"Answer\"]:\n",
    "            count += 1\n",
    "            # print(\"\\nCorrect!\")\n",
    "        # else:\n",
    "            # print(\"\\nIncorrect.\")\n",
    "\n",
    "        print()\n",
    "        print()\n",
    "    score.append(count)  \n",
    "    count=0 \n",
    "        \n",
    "print(f\"\\nYour final score is {sum(score)}/{len(questions['HR Section']) + len(questions['Technical Section'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1_Qq7Ss633mN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Td5PYGez33fn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wfzxs-wV33XP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monu8u458hq_"
   },
   "source": [
    "## 2.2: Descriptive interview round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2g8m1cn13q3w"
   },
   "outputs": [],
   "source": [
    "# Import the text from the saved file\n",
    "with open('interview.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jlOvHato3q3x"
   },
   "outputs": [],
   "source": [
    "# Defining question templates\n",
    "templates = [\n",
    "    \"What is {subject} and what are the benefits of {subject}?\",\n",
    "    \"Can you explain {subject}?\",\n",
    "    \"How does {subject} work and given an application of {subject}?\",\n",
    "    \"What are the applications of {subject}?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IK_Rs1Ha3q3x"
   },
   "outputs": [],
   "source": [
    "# Define a function to extract keywords\n",
    "def extract_keywords(doc, ngram_range=(1,3), min_freq=2):\n",
    "    \"\"\"Extract keywords from a Spacy Doc object using a given ngram_range and minimum frequency\"\"\"\n",
    "    keywords = []\n",
    "    for n in range(ngram_range[0], ngram_range[1]+1):\n",
    "        ngrams = [doc[i:i+n] for i in range(len(doc)-n+1)]\n",
    "        freq = {}\n",
    "        for ngram in ngrams:\n",
    "            if all(word.is_alpha and not word.is_stop and not word.is_punct and (word.pos_ == \"NOUN\" or word.pos_ == \"PROPN\") for word in ngram):\n",
    "                freq[ngram.text.lower()] = freq.get(ngram.text.lower(), 0) + 1\n",
    "        for ngram, f in freq.items():\n",
    "            if f >= min_freq:\n",
    "                keywords.append(ngram)\n",
    "    return keywords\n",
    "\n",
    "# this function gives us two and three words, keywords\n",
    "def two_three_keywords():\n",
    "\n",
    "    # Extract unigrams, bigrams, and trigrams with a minimum frequency of 2\n",
    "    keywords = set(extract_keywords(doc, ngram_range=(2,4), min_freq=1))\n",
    "\n",
    "    keywords_two = set()\n",
    "    keywords_three = set()\n",
    "\n",
    "    for word in keywords:\n",
    "        if len(word.strip().split(' ')) == 3:\n",
    "            keywords_three.add(word)\n",
    "        if len(word.strip().split(' ')) == 2:\n",
    "            keywords_two.add(word)\n",
    "\n",
    "    return list(keywords_two) + list(keywords_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "q4uoAqlF3q3x"
   },
   "outputs": [],
   "source": [
    "# Creating questions\n",
    "\n",
    "def getting_questions(templates, n=5):\n",
    "\n",
    "    questions = []\n",
    "    keys = two_three_keywords()\n",
    "    keys = random.sample(keys, n)\n",
    "    print(keys)\n",
    "\n",
    "    i=0\n",
    "    while i < 5:\n",
    "        question = random.choice(templates)\n",
    "        question = question.format(subject=keys[i])\n",
    "        questions.append(question)\n",
    "        i+=1\n",
    "\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEta1tpPEMYj",
    "outputId": "04f8a82c-6ee6-46eb-eafe-a4c30b76adb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['squares method', 'feature importance analysis', 'training data', 'data points', 'regression problems']\n",
      "\n",
      "Welcome to the second round of interview!\n",
      "\n",
      "\n",
      "Hello, Bot! Congratulations for qualifying to this round!\n",
      "\n",
      "This is a descriptive round, please type your answer in the space provided. \n",
      "Let's start with Technical questions.\n",
      "\n",
      "\n",
      "Q: How does squares method work and given an application of squares method?\n",
      "Ans: 1-IDK\n",
      "\n",
      "Q: How does feature importance analysis work and given an application of feature importance analysis?\n",
      "Ans: 2-IDK\n",
      "\n",
      "Q: What is training data and what are the benefits of training data?\n",
      "Ans: 3-IDK\n",
      "\n",
      "Q: What are the applications of data points?\n",
      "Ans: 4-IDK\n",
      "\n",
      "Q: What are the applications of regression problems?\n",
      "Ans: 5-IDK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "def generate_answers(questions, doc):\n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "    max_chunk_size = 450\n",
    "    chunked_text = [doc[i:i+max_chunk_size] for i in range(0, len(doc), max_chunk_size)]\n",
    "    #print(chunked_text[0])\n",
    "    print(\"\\nWelcome to the second round of interview!\\n\")\n",
    "    # candidate_name = input(\"What is your name? \")\n",
    "    print(\"\\nHello, \" + candidate_name + \"! Congratulations for qualifying to this round!\")\n",
    "    print(\"\\nThis is a descriptive round, please type your answer in the space provided. \\nLet's start with Technical questions.\\n\\n\")\n",
    "\n",
    "    answer = \"\"\n",
    "    for question in questions:\n",
    "\n",
    "        user_answer = input(f\"Q: {question}\\nAns: \")\n",
    "        print()\n",
    "\n",
    "        for text in chunked_text:\n",
    "\n",
    "            # Tokenize the input\n",
    "            inputs = tokenizer.encode_plus(question, str(text), add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "            # Answer the question\n",
    "            answer_start_scores, answer_end_scores = model(**inputs).values()\n",
    "            answer_start = torch.argmax(answer_start_scores)\n",
    "            answer_end = torch.argmax(answer_end_scores) + 1\n",
    "            answer_chunk = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "            answer += answer_chunk.strip() + \" \"\n",
    "\n",
    "        answer = re.sub(r'\\[CLS\\].*?\\[SEP\\]', '', answer)\n",
    "        answer = re.sub(r'\\[CLS\\]', '', answer)\n",
    "\n",
    "        results.append((question, answer, user_answer))\n",
    "\n",
    "        # Print the answer\n",
    "        # print('Q:',question)\n",
    "        # print('Ans:',answer)\n",
    "        # print()\n",
    "        answer = ''\n",
    "\n",
    "questions = getting_questions(templates, 5)\n",
    "generate_answers(questions, doc)\n",
    "\n",
    "tech_filename = \"technical_descriptive.csv\"\n",
    "with open(tech_filename, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Question\", \"Model Answer\", \"User Answer\"])\n",
    "    for row in results:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVx2KlO7Keyt",
    "outputId": "c4c7484a-e49b-45db-986e-9058392b5ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to technical_descriptive.csv\n",
      "The CSV file has been saved to: /content/technical_descriptive.csv\n"
     ]
    }
   ],
   "source": [
    "# If we want to see the csv's path\n",
    "import os\n",
    "print(f\"Results saved to {tech_filename}\")\n",
    "print(f\"The CSV file has been saved to: {os.getcwd()}/{tech_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9QKHlbrJLb1",
    "outputId": "cc21d6c6-5fd8-4f64-d15c-73598af11834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question  \\\n",
      "0  How does squares method work and given an appl...   \n",
      "1  How does feature importance analysis work and ...   \n",
      "2  What is training data and what are the benefit...   \n",
      "3          What are the applications of data points?   \n",
      "4  What are the applications of regression problems?   \n",
      "\n",
      "                                        Model Answer User Answer  \n",
      "0  finds the values of m and b that minimize the ...       1-IDK  \n",
      "1  once the algorithm has learned these patterns,...       2-IDK  \n",
      "2  allowing them to identify patterns and relatio...       3-IDK  \n",
      "3  image and speech recognition, natural language...       4-IDK  \n",
      "4  image and speech recognition, natural language...       5-IDK  \n"
     ]
    }
   ],
   "source": [
    "# Reading csv file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r'/content/technical_descriptive.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSmrWOcWrdSO",
    "outputId": "236324a7-7c1c-4913-d416-19b5605209ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good job, Bot.\n",
      "\n",
      "Now let's start with HR questions.\n",
      "\n",
      "\n",
      "Q: Tell me about yourself?\n",
      "Ans: 1-idk\n",
      "\n",
      "Q: What are your weakness and strength?\n",
      "Ans: 2-idk\n",
      "\n",
      "Q: Where do you see yourself in 5 years?\n",
      "Ans: 3-idk\n",
      "\n",
      "Well done Bot.\n"
     ]
    }
   ],
   "source": [
    "print(\"Good job, \" + candidate_name + \".\\n\")\n",
    "print(\"Now let's start with HR questions.\\n\\n\")\n",
    "\n",
    "# load json file\n",
    "with open('mcq_questiosn.json', 'r') as f:\n",
    "    questions = json.load(f)\n",
    "\n",
    "# extract questions from HR_Desc section\n",
    "hr_questions = list(questions[\"HR_Desc\"].keys())\n",
    "\n",
    "# create empty list to store answers\n",
    "answers = []\n",
    "\n",
    "# loop through questions and prompt user for answers\n",
    "for question in hr_questions:\n",
    "    # user_answer = input(question + \"\\n\")\n",
    "    user_answer = input(f\"Q: {question}\\nAns: \")\n",
    "    answers.append(user_answer)\n",
    "    print()\n",
    "\n",
    "# write questions and answers to CSV file\n",
    "hr_filename = \"hr_descriptive.csv\"\n",
    "with open(hr_filename, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Question\", \"Answer\"])\n",
    "    for i in range(len(hr_questions)):\n",
    "        writer.writerow([hr_questions[i], answers[i]])\n",
    "\n",
    "print(\"Well done \" + candidate_name + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3FzIjOXfrdjd",
    "outputId": "929f3195-f0a7-4993-91be-2fbe8130b82c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to hr_descriptive.csv\n",
      "The CSV file has been saved to: /content/hr_descriptive.csv\n"
     ]
    }
   ],
   "source": [
    "# If we want to see the csv's path\n",
    "print(f\"Results saved to {hr_filename}\")\n",
    "print(f\"The CSV file has been saved to: {os.getcwd()}/{hr_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6WHdQzT98KN",
    "outputId": "e377b908-32de-47ee-b06e-1759d5ed4087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Question Answer\n",
      "0                Tell me about yourself?  1-idk\n",
      "1   What are your weakness and strength?  2-idk\n",
      "2  Where do you see yourself in 5 years?  3-idk\n"
     ]
    }
   ],
   "source": [
    "# Reading csv file\n",
    "df = pd.read_csv('/content/hr_descriptive.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "644baTdag37C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pbAB-ViQGweR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "X7RRclNkGwoH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwk-js-1g37C"
   },
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NPJFIH8lH4pl"
   },
   "outputs": [],
   "source": [
    "# Cumulative scoring\n",
    "\n",
    "# Final score of the candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "O9UQkseEsFqN"
   },
   "outputs": [],
   "source": [
    "def HR_Scoring(user_answer_doc, hr_question_doc):\n",
    "    \n",
    "    # Calculate the cosine similarity between the answer and the HR question vectors\n",
    "    similarity = cosine_similarity(user_answer_doc.vector.reshape(1,-1), hr_question_doc.vector.reshape(1,-1))\n",
    "\n",
    "    return similarity[0][0]\n",
    "\n",
    "\n",
    "def Tech_Scoring(user_answer_doc, model_answer_doc):\n",
    "    \n",
    "    # Calculate the cosine similarity between the answer and the HR question vectors\n",
    "    similarity = cosine_similarity(user_answer_doc.vector.reshape(1,-1), model_answer_doc.vector.reshape(1,-1))\n",
    "\n",
    "    return similarity[0][0]\n",
    "\n",
    "\n",
    "# 50-30-20(Technical, HR, Resume)\n",
    "def scoring(score, df):\n",
    "    # Load the Spacy language model\n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    questions = df['Question'].values\n",
    "\n",
    "    for i in range(0, len(questions)):\n",
    "\n",
    "        # Tokenize and process the answer and the HR question\n",
    "        user_answer_doc = nlp(df['User Answer'][i])\n",
    "        model_answer_doc = nlp(df['Model Answer'][i])\n",
    "\n",
    "        temp1 = HR_Scoring()\n",
    "        temp2 = Tech_Scoring(user_answer_doc, model_answer_doc)\n",
    "\n",
    "    tech_desc_score += temp2\n",
    "    hr_desc_score += temp1\n",
    "\n",
    "    # total score out of 10\n",
    "    total_tech_score = score[0] + tech_desc_score\n",
    "    total_hr_score = score[1] + hr_desc_score\n",
    "\n",
    "    return total_tech_score*5, total_hr_score*3 , random.randrange(0, 10, 1)*2   # Vijay to complete the resume scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ky3rlnx_g37D"
   },
   "source": [
    "##### Fuzzy Inference System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7vKcaWpdg37D"
   },
   "outputs": [],
   "source": [
    "def FIS(score, df):\n",
    "    # getting scores\n",
    "    tech, hr, resume = scoring(score, df)\n",
    "\n",
    "    # Define input variables\n",
    "    resume = ctrl.Antecedent(np.arange(0, 21, 1), 'resume')\n",
    "    technical = ctrl.Antecedent(np.arange(0, 51, 1), 'technical')\n",
    "    HR = ctrl.Antecedent(np.arange(0, 31, 1), 'hr')\n",
    "\n",
    "    # Define output variable\n",
    "    score = ctrl.Consequent(np.arange(0, 101, 1), 'score')\n",
    "\n",
    "    # Generate fuzzy membership functions for input variables\n",
    "    resume['low'] = fuzz.trimf(resume.universe, [0, 0, 10])\n",
    "    resume['medium'] = fuzz.trimf(resume.universe, [0, 10, 20])\n",
    "    resume['high'] = fuzz.trimf(resume.universe, [10, 20, 20])\n",
    "    technical['low'] = fuzz.trimf(technical.universe, [0, 0, 25])\n",
    "    technical['medium'] = fuzz.trimf(technical.universe, [0, 25, 50])\n",
    "    technical['high'] = fuzz.trimf(technical.universe, [25, 50, 50])\n",
    "    HR['low'] = fuzz.trimf(HR.universe, [0, 0, 15])\n",
    "    HR['medium'] = fuzz.trimf(HR.universe, [0, 15, 30])\n",
    "    HR['high'] = fuzz.trimf(HR.universe, [15, 30, 30])\n",
    "\n",
    "    # Generate fuzzy membership function for output variable\n",
    "    score['low'] = fuzz.trimf(score.universe, [0, 0, 50])\n",
    "    score['medium'] = fuzz.trimf(score.universe, [0, 50, 100])\n",
    "    score['high'] = fuzz.trimf(score.universe, [50, 100, 100])\n",
    "\n",
    "    # Define the rules for grading the resume\n",
    "    rule1 = ctrl.Rule(resume['low'] & technical['low'] & HR['low'], score['low'])\n",
    "    rule2 = ctrl.Rule(resume['low'] & technical['low'] & HR['medium'], score['low'])\n",
    "    rule3 = ctrl.Rule(resume['low'] & technical['low'] & HR['high'], score['low'])\n",
    "    rule4 = ctrl.Rule(resume['low'] & technical['medium'] & HR['low'], score['medium'])\n",
    "    rule5 = ctrl.Rule(resume['low'] & technical['medium'] & HR['medium'], score['medium'])\n",
    "    rule6 = ctrl.Rule(resume['low'] & technical['medium'] & HR['high'], score['medium'])\n",
    "    rule7 = ctrl.Rule(resume['medium'] & technical['high'] & HR['low'], score['medium'])\n",
    "    rule8 = ctrl.Rule(resume['medium'] & technical['high'] & HR['medium'], score['high'])\n",
    "    rule9 = ctrl.Rule(resume['medium'] & technical['high'] & HR['high'], score['high'])\n",
    "    rule10 = ctrl.Rule(resume['medium'] & technical['low'] & HR['low'], score['low'])\n",
    "    rule11 = ctrl.Rule(resume['medium'] & technical['low'] & HR['medium'], score['low'])\n",
    "    rule12 = ctrl.Rule(resume['medium'] & technical['low'] & HR['high'], score['medium'])\n",
    "    rule13 = ctrl.Rule(resume['high'] & technical['medium'] & HR['low'], score['medium'])\n",
    "    rule14 = ctrl.Rule(resume['high'] & technical['medium'] & HR['medium'], score['medium'])\n",
    "    rule15 = ctrl.Rule(resume['high'] & technical['medium'] & HR['high'], score['medium'])\n",
    "    rule16 = ctrl.Rule(resume['high'] & technical['high'] & HR['low'], score['medium'])\n",
    "    rule17 = ctrl.Rule(resume['high'] & technical['high'] & HR['medium'], score['high'])\n",
    "    rule18 = ctrl.Rule(resume['high'] & technical['high'] & HR['high'], score['high'])\n",
    "\n",
    "    # Define control system and simulate\n",
    "    score_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9, rule10, rule11, rule12, rule13, rule14, rule15, rule16, rule17, rule18])\n",
    "    score_sim = ctrl.ControlSystemSimulation(score_ctrl)\n",
    "\n",
    "    # Pass input values to simulation\n",
    "    score_sim.input['resume'] = resume\n",
    "    score_sim.input['technical'] = tech\n",
    "    score_sim.input['hr'] = hr\n",
    "\n",
    "    # Calculate output\n",
    "    score_sim.compute()\n",
    "\n",
    "    # Print result\n",
    "    print(\"Candidates Score:\", score_sim.output['score'])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "518071c88b4194aee059da36c8bb8c7f03edabff5e31c99a4f47aa39aa99e517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
